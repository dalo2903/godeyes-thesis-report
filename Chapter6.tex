\chapter{Related Works}
\label{chap:relatedwork}

In Chapter 6, we describe a few recent works relating to river runoff prediction and boiler efficiency optimization.

\minitoc

\section{River Runoff Prediction}

For any country in the world, river runoff prediction is very important for water resources planning and management. In the past few decades, river runoff prediction has been studied by a large number of scientists in many fields, especially computer science \cite{ANN:ref_87, ANN:ref_88}. Generally, models that are used to predict river runoff can be classed into the two main groups: physical-based models and data-driven models. Typically, the first approach has a complex structure, and requires rather substantial mathematical knowledge and diverse calibration data. In the environmental field, people often use these kind of models in modeling water resources, including runoff of rivers. In \cite{swatref01, swatref05, swatref02, swatref03, swatref04, swatref06} the authors proposed methods using Soil and Water Assessment Tool (SWAT) and GIS techniques to model the current and future changes in water resources. The main disadvantage of these methods is that SWAT requires diverse kinds of data, ranging from climate and water resource data to soil map data. As a result, employing SWAT is costly and time-consuming. Moreover, in Vietnam, much environmental and natural data are not available or are unreliable. Consequently, the use of SWAT for modeling river runoff is only barely acceptable \cite{swatref01, swatref05}. 

In 2000, Bart Nijssen \textit{et al.} introduced their experimental results of predicting the discharge from global rivers \cite{ANN:ref_85}. They used Macroscale Hydrological Models (MHMs) to predict runoff from several large rivers in the world. The authors pointed out that the calibration of MHMs is a time-consuming process and thus unfeasible for modeling large basins. The experimental results of MHMs were also poor, with an average relative (monthly) RMSE of 70\%. In addition, in \cite{ANN:ref_82}, Thomas M. Hopson and Peter J. Webster utilized a hydrologic model initialized by NASA and NOAA to forecast 1-to-10-day horizons for major river basins of Bangladesh. The authors concluded that the accuracy of forecasted results depends on three important factors: the quality of weather predictions, the availability of a range of satellite precipitation products to initialize the modeled watershed states and the incorporation of all data sources used in the model. 

In short, most physical-based models require a significant amount of calibration data, and a high degree of expertise and experience; thus it is difficult to utilize these models to accurately predict and forecast river runoff.

In contrast, data-driven models require minimal information, are easy to develop, and have been found to be accurate in various applications of hydrologic prediction \cite{ANN:ref_64, ANN:ref_73, ANN:ref_80, ANN:ref_81, ANN:ref_86, ANN:ref_87, ANN:ref_88}. To date, several advanced data-driven models have been proposed to predict and forecast river runoff, e.g., support vector machines \cite{ANN:ref_64, ANN:ref_80, ANN:ref_86}, CART models \cite{ANN:ref_73}, Bayesian models \cite{ANN:ref_73} and neural networks \cite{ANN:ref_88, ANN:ref_87}. Among those data-driven models, neural network model has proved its strength in simulating the sophisticated relationships of many different kinds of complex data, especially hydrologic data. 

Although researchers have introduced several novel improvements of neural networks for some specific cases of river runoff prediction \cite{rein:ref_01, ANN:ref_66, ANN:ref_67, ANN:ref_75, ANN:ref_79, ANN:ref_78, ANN:ref_90}, it is hard to identify a single neural network model that achieves optimal results on the overall problem domain. In other words, depending on a specific problem, authors will experimentally explore the approximations of the optimal models. For example, in 2010, a study of Lance E. Besaw \textit{et al.} \cite{ANN:ref_65} demonstrated that the use of neural networks could effectively predict stream-flow of the Winooski River in northern Vermont, U.S.A. Lance E. Besaw \textit{et al.} pointed out that predictions based on hourly data are more efficient than using daily data because important relationships between climate and the runoff were lost the latter case.

Moreover, in 2009, Saman Razavi \textit{et al.} \cite{ANN:ref_66} also showed that using temporal neural networks to predict flows in the Karoon basin in south-western Iran proved more effective than traditional methods such as ARMA. In other studies \cite{ANN:ref_74} and \cite{ANN:ref_75}, the neural network model and its hybrid models were used to simulate and predict runoff in the Ebro River Basin in Spain and the Aghchai River in Iran, respectively. The authors noted that their proposed methods were appropriate for these case studies. In the review of \cite{ANN:ref_87}, the authors highlighted a robustly increasing trend of utilizing neural networks for the prediction of water resources. The authors also noted that in the period of 1999-2010, among 210 high-impact papers focusing on the prediction and forecasting of water resources, 165 papers dealt with river runoff prediction. The case study areas in these papers are located throughout the world, in regions such as Vietnam, the UK, the U.S., Italy, Spain, China, Brazil, etc.

A great many researchers have attempted to tackle challenge of the river runoff prediction by utilizing neural networks. Some efforts were directed towards the comparisons of neural networks with other advanced methods, or hybrid models of neural networks combined with various theories. In \cite{ANN:ref_64}, Zhibin He \textit{et al.} studied and compared three models: ANN, adaptive neuro fuzzy inference system (ANFIS) and support vector machine (SVM) and used them to predict the Heihe River runoff in China. The authors concluded that all three models can be applied successfully to establish accurate and reliable river runoff prediction. In 2014, Muhammad Shoaib, Asaad Y. Shamseldin, and Bruce W. Melville studied wavelet-based neural network models for rainfall-runoff modeling \cite{ANN:ref_91}. Two neural network models, consisting of Multilayer Perceptron Neural Network (MLPNN) and Radial Basis Function Neural Network (RBFNN), were combined with continuous wavelet and discrete wavelet transformation types. Experiments were conducted on the data from the Brosna catchment in Ireland showed that the wavelet transformation can significantly increase the performance of MLPNN and RBFNN. In other studies, Adam P. Piotrowski and Jaroslaw J. Napiorkowski attempted to model the Annapolis River runoff and studied the comparison of methods to avoid over-fitting in neural networks training \cite{ANN:ref_72}. Roohollah Noori \textit{et al.} compared the performance of ANN and principal-component analysis of multivariate linear regression models to predict the Sofichay River runoff \cite{ANN:ref_89}.

A few years ago, one interesting approach was to combine neural networks with evolutionary algorithms such as Genetic Algorithm (GA) \cite{ANN:ref_67}, Particle Swarm Optimization (PSO) \cite{ANN:ref_79, ANN:ref_78, ANN:ref_90}. The approach was utilized to successfully tackle various problems, and quickly proved appropriate for river runoff prediction. Most the experimental results of these publications showed that the hybrids of evolutionary algorithms and neural networks outperform traditional neural networks in predicting and forecasting river runoff. In addition, another interesting technique is chaotic expressions, which are responsible for highlighting temporal characteristics of time series data generally and river runoff data particularly. In \cite{ANN:ref_05, ANN:ref_07, ANN:ref_17}, the authors applied chaotic expressions to reconstruct a new kind of chaotic data, namely phase space, from the original time series. Then they used a neural network model and its hybrid models to explore within the phase space. 

In summary, to meet the challenges of river runoff prediction, we have a large number of candidate methods: linear regressions, nonlinear regressions, support vector machines, fuzzy systems, neural networks and so on. Although neural networks have been used widely, we cannot conclude that neural network model is the most superior method for the overall problem domain. Depending on a specific problem (with a corresponding specific dataset), we must analyze (manually, empirically, etc.) the main characteristics of the dataset to decide which methods are most suitable. The we verify this by experiments. In the reviewed works, we realize that most case studies involve rivers with sloping terrain. These rivers often produce runoff data that varies greatly over time, especially seasonally. Furthermore, most of these rivers locate in mountains; consequently, sometimes natural disasters such as storms, droughts, and landslides occur. As a result, the river runoff data have large margins and contain a few anomalies; it is difficult to predict and forecast these noisy data. The Srepok River, which is chosen as a case study in this thesis, also has a sloping terrain. Therefore, the neural network model and associated hybrid models seem to be suitable methods to predict the Srepok runoff.

\paragraph{A short survey of Vietnamese research.}

In Vietnam, most research which has utilized techniques of computer science to address problems of climate change and hydrology are barely acceptable - not only in theory, but in practice. So far, there have been few significant publications addressing combinations of computer science and hydrology, and most of them are local publications. In 2007, Pham Thi Hoang Nhung, Quang Thuy Ha studied how to use Artificial Neural Network in predicting the runoff of Hoa Binh Lake within 10 days \cite{ANN:ref_68}. The authors employed genetic algorithms for learning an ANN to predict the runoff. Nguyen Thanh Son \textit{et al.} studied the effect of climate change on the water resources of the Nhue River basin \cite{ANN:ref_69}. The authors utilized climate change scenarios combined with the North American Mesoscale (NAM) model. They also conducted some simulations of climate change effects on water resources and drew several significant assessments. In \cite{ANN:ref_70}, Tran Thanh Xuan studied the impacts of climate change on river runoff and indicated which ones have maximum influence. In \cite{ANN:ref_71}, the author employed ANNs to predict rainfall and river runoff and thus minimize drought within the river basins in the Central Highland of Vietnam. The results showed that their proposed method was effective in predicting river runoff.

\section{Boiler Efficiency Optimization}

Regarding production process optimization at a fertilizer plant such as Phu My, several optimal approaches in literature can be divided into three categories \cite{boi:ref_09, boi:ref_12}:

\begin{enumerate}

\item Analyzing production and operating models based on thermodynamics and chemistry.
\item Applying soft computing methods such as fuzzy logic, evolutionary computing, artificial neural network, etc to seek optimal solutions.
\item Combining the approaches mentioned above.

\end{enumerate}

The drawback of approaches belonging to the first category is the lack of automatically applying analysis tools to solve complex mathematical formulas with many sensitive parameters in a constantly changing environment. Particularly regarding production process optimization at Phu My Fertilizer Plant, the construction of computational and comprehensive combustion models should be sophisticated due to many complex expressions that change under ambient conditions \cite{boi:ref_08}. Moreover, such constructed models lack characteristics, considered as input parameters, of a combustion process changing over time. As the result, the optimization process based on those constructed models produce increasing errors over the long term. 

Many efforts have been invested into approaches belonging to the second and third categories. Some applications offering functions such as soft sensors have been developed in the literature. A soft sensor, which may be called a virtual sensor, consists of computer software collecting multiple values of parameters correlated with each other in a particular technological process. One can mine the correlation between those parameters to derive knowledge; that knowledge can be exploited to optimize industrial processes as well as forecasting particular problems. Some notable applications including soft sensors are listed as follows.

\begin{itemize}

\item [$\bullet$] The first one was developed by Yokogawa Corporation and has four soft sensors for advanced process control. One of those sensors, namely RQE, applies artificial neural networks in modeling \cite{boi:ref_06}.
\item [$\bullet$] The second one was developed by Emerson Corporation, namely DeltaV, and includes vir-tual sensors employing artificial neural networks (ANN) \cite{boi:ref_03}.
\item [$\bullet$] The third was developed by Aspen Technology Inc. The software suite AspenONE Advanced Process Control for Chemicals includes many soft sensors, e.g., Aspen Inferential Qualities (Aspen IQ) applying Partial Least Square  PLS, Fuzzy PLS, ANN, and a hybrid of PLS and ANN for data analysis and modeling \cite{boi:ref_05}.
\item [$\bullet$] The fourth, namely Kn3, was developed by General Electric Corporation. It applies ANN and data mining to build a sensor for optimizing an engine factory \cite{boi:ref_07}. 

\end{itemize}

In general, one can see a soft sensor as a data mining application combined with specific industrial knowledge to solve forecasting or estimating problems. Data mining techniques, especially neural networks and clustering algorithms, are used relatively frequently. The applications mentioned above have been commercialized and deployed for many years; they have proven their efficiency in terms of economic profits and productivity. Moreover, most of the commercial applications contain the functions of observing and optimizing boiler efficiency (so-called combustion efficiency).

Although the challenges of production process optimization in general, and boiler efficiency optimization in particular, are interesting, there have been few publications utilizing computer science to deal with the challenges. In \cite{boi:ref_13}, a simple computer software program was developed to perform simultaneous optimization of the stack and hot air temperatures. The authors showed that the stoichiometric ratio and steam power significantly impact overall boiler efficiency. 

In \cite{boi:ref_09}, Andrew Kusiak and Zhe Song presented an application of data mining techniques to optimize boiler efficiency. The authors applied a K-means algorithm to cluster the historical data into a set of control signatures, called a knowledge base. To deal with the real-time optimization of boiler efficiency, they utilized a temporal linear regression model that explores the knowledge base to identify an optimal control setting that can improve the boiler efficiency. A neural network model was used to simulate a real boiler and verify the effectiveness of the suggested optimal control setting. Without performing live testing, which is expensive and time-consuming, the authors concluded that their approach was effective and significantly increased boiler efficiency. To improve the performance of this approach, in \cite{boi:ref_12}, Andrew Kusiak and Zhe Song applied some methods of variable selection to refine the control parameters that take part in the approach as well as assigning weights to the variables. They also concluded that both proposed methods performed well in terms of improving boiler efficiency.

The temporal linear regression model used in \cite{boi:ref_09} and \cite{boi:ref_12} has disadvantages in that it only gives good results for short-term simulation and 1-step-ahead estimation. That means the model can only estimate the maximal boiler efficiency at time $t+1$ from the boiler efficiency at time $t$ and the estimated control parameters at time $t+1$. It is not able to provide a multi-step-ahead (MSA) estimate of the boiler efficiency during run-time. Moreover, the coefficients of this linear regression model are inflexibly updated during run-time, whereas the boiler efficiency is nonlinear and non-stationary. Therefore, to improve the boiler efficiency, it is necessary to build an engine that can not only model the nonlinear and non-stationary characteristics of boiler efficiency, but also estimate (forecast) MSA boiler efficiency in run-time.  

When building a forecasting engine, people are often unsure how to choose a suitable strategy of MSA forecasting. Among many different strategies, iterated forecasting and direct forecasting are quite common \cite{ANN:ref_32,ANN:ref_33}. For iterated forecasting, one-step-ahead forecasting is repeated $n$ times to accomplish the task of $n$-step-ahead forecasting. The direct method attempts to forecast directly at time $t+n$. However, both strategies retain a few drawbacks. Iterative forecasting with no reinforced learning or supervision in the surrounding environments, thus it gradually provides more inaccurate results when we compare the simulated data with observed data. In other words, after each iteration, the forecasting result has an error. The error increases exponentially over time; the larger $n$ is, the worse the error. In contrast, for direct forecasting, the relationship between the data at $t$ and $t+n$ is vague and it is difficult to explore the obscure relationship by employing a regression method such as a neural network model. In many practical applications, people usually encounter a problem of how to choose the most appropriate $n$, and most solutions are based on experimentation. So in \cite{ANN:ref_05,ANN:ref_07,ANN:ref_17}, the authors applied some chaotic formulas to enrich the temporal information of observed data; that approach seems to offer a significant improvement regarding the drawback of direct forecasting. However, the major disadvantage of the chaotic solution is that the optimal $n$ value is nearly unique for a specific data. Due to the goal of MSA forecasting, $n$ must be flexibly varied; the chaotic approach becomes inappropriate.

Reinforcement learning (RL) has attracted several researchers and has been applied widely to tackle problems of run-time simulation during the past few decades. In particular, RL has been widely applied to learning artificial neural networks \cite{rein:ref_01,rein:ref_02,rein:ref_03}. In fact, RL is a broad class of optimal controlling methods based on estimating value functions from experience, simulation, or search \cite{rein:ref_04}. RL enhances the adaption of control systems based on the latest change in the surrounding environment. Generally, RL can be classified into three categories: dynamic programming, Monte Carlo methods and temporal difference learning that is a combination of the two previous categories \cite{rein:ref_05}. Each method has its advantages and disadvantages. Depending on a specific problem, we can choose the most appropriate method. However, applying RL for ANNs seems to be more suitable for solving control system problems such as robot controlling, vehicle controlling, game programming, etc. than for solving problems of time series forecasting \cite{rein:ref_06,rein:ref_07}. In \cite{rein:ref_01}, the authors introduced a different kind of reinforcement learning for ANNs, namely, a multi-step-ahead (MSA) reinforced real-time recurrent learning algorithm for recurrent neural networks (R-RTRL NN). Through experiments, the authors applied R-RTRL NN for MSA flood forecasting, which is a type of time series forecasting. The authors also noted that the method outperformed two other kinds of ANNs. 